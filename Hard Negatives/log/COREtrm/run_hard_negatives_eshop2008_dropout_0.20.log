Wed 18 Feb 2026 20:39:41 INFO  
General Hyper Parameters:
gpu_id = 0
use_gpu = True
seed = 2020
state = INFO
reproducibility = True
data_path = ../dataset/eshop2008
checkpoint_dir = saved
show_progress = True
save_dataset = False
dataset_save_path = None
save_dataloaders = False
dataloaders_save_path = None
log_wandb = False

Training Hyper Parameters:
epochs = 20
train_batch_size = 2048
learner = adam
learning_rate = 0.001
neg_sampling = None
eval_step = 1
stopping_step = 5
clip_grad_norm = None
weight_decay = 0.0
loss_decimal_place = 4

Evaluation Hyper Parameters:
eval_args = {'order': 'TO', 'train_neg_sample_args': None, 'split': {'RS': [0.8, 0.1, 0.1]}, 'group_by': 'user', 'mode': 'full'}
repeatable = True
metrics = ['Recall', 'MRR']
topk = [20]
valid_metric = MRR@20
valid_metric_bigger = True
eval_batch_size = 2048
metric_decimal_place = 4

Dataset Hyper Parameters:
field_separator = 	
seq_separator =  
USER_ID_FIELD = session_id
ITEM_ID_FIELD = item_id
RATING_FIELD = rating
TIME_FIELD = timestamp
seq_len = None
LABEL_FIELD = label
threshold = None
NEG_PREFIX = neg_
load_col = {'inter': ['session_id', 'item_id_list', 'item_id']}
unload_col = None
unused_col = None
additional_feat_suffix = None
rm_dup_inter = None
val_interval = None
filter_inter_by_user_or_item = True
user_inter_num_interval = [0,inf)
item_inter_num_interval = [0,inf)
alias_of_user_id = None
alias_of_item_id = ['item_id_list']
alias_of_entity_id = None
alias_of_relation_id = None
preload_weight = None
normalize_field = None
normalize_all = None
ITEM_LIST_LENGTH_FIELD = item_length
LIST_SUFFIX = _list
MAX_ITEM_LIST_LENGTH = 50
POSITION_FIELD = position_id
HEAD_ENTITY_ID_FIELD = head_id
TAIL_ENTITY_ID_FIELD = tail_id
RELATION_ID_FIELD = relation_id
ENTITY_ID_FIELD = entity_id
benchmark_filename = ['train', 'valid', 'test']

Other Hyper Parameters: 
wandb_project = recbole
require_pow = False
MODEL_TYPE = ModelType.SEQUENTIAL
device = cuda
embedding_size = 100
inner_size = 256
n_layers = 2
n_heads = 2
hidden_dropout_prob = 0.5
attn_dropout_prob = 0.5
hidden_act = gelu
layer_norm_eps = 1e-12
initializer_range = 0.02
loss_type = CE
sess_dropout = 0.2
item_dropout = 0.2
temperature = 0.07
use_hard_negatives = True
hard_neg_k = 64
hard_neg_lambda = 0.2
train_neg_sample_args = {'strategy': 'none'}
MODEL_INPUT_TYPE = InputType.POINTWISE
eval_type = EvaluatorType.RANKING
eval_neg_sample_args = {'strategy': 'full', 'distribution': 'uniform'}


Wed 18 Feb 2026 20:39:43 INFO  eshop2008
The number of users: 141443
Average actions of users: 1.0
The number of items: 214
Average actions of items: 664.0469483568075
The number of inters: 141442
The sparsity of the dataset: 99.53271358410551%
Remain Fields: ['session_id', 'item_id_list', 'item_id', 'item_length']
Wed 18 Feb 2026 20:39:44 INFO  [Training]: train_batch_size = [2048] negative sampling: [None]
Wed 18 Feb 2026 20:39:44 INFO  [Evaluation]: eval_batch_size = [2048] eval_args: [{'order': 'TO', 'train_neg_sample_args': None, 'split': {'RS': [0.8, 0.1, 0.1]}, 'group_by': 'user', 'mode': 'full'}]
Wed 18 Feb 2026 20:39:44 INFO  COREtrm(
  (sess_dropout): Dropout(p=0.2, inplace=False)
  (item_dropout): Dropout(p=0.2, inplace=False)
  (item_embedding): Embedding(214, 100, padding_idx=0)
  (loss_fct): CrossEntropyLoss()
  (net): TransNet(
    (position_embedding): Embedding(50, 100)
    (trm_encoder): TransformerEncoder(
      (layer): ModuleList(
        (0-1): 2 x TransformerLayer(
          (multi_head_attention): MultiHeadAttention(
            (query): Linear(in_features=100, out_features=100, bias=True)
            (key): Linear(in_features=100, out_features=100, bias=True)
            (value): Linear(in_features=100, out_features=100, bias=True)
            (softmax): Softmax(dim=-1)
            (attn_dropout): Dropout(p=0.5, inplace=False)
            (dense): Linear(in_features=100, out_features=100, bias=True)
            (LayerNorm): LayerNorm((100,), eps=1e-12, elementwise_affine=True)
            (out_dropout): Dropout(p=0.5, inplace=False)
          )
          (feed_forward): FeedForward(
            (dense_1): Linear(in_features=100, out_features=256, bias=True)
            (dense_2): Linear(in_features=256, out_features=100, bias=True)
            (LayerNorm): LayerNorm((100,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.5, inplace=False)
          )
        )
      )
    )
    (layer_norm): LayerNorm((100,), eps=1e-12, elementwise_affine=True)
    (dropout): Dropout(p=0.5, inplace=False)
    (fn): Sequential(
      (0): Linear(in_features=200, out_features=100, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=100, out_features=1, bias=True)
    )
  )
)
Trainable parameters: 231513
Wed 18 Feb 2026 20:39:48 INFO  epoch 0 training [time: 2.59s, train loss: 329.4125]
Wed 18 Feb 2026 20:39:48 INFO  epoch 0 evaluating [time: 0.17s, valid_score: 0.080600]
Wed 18 Feb 2026 20:39:48 INFO  valid result: 
recall@20 : 0.397    mrr@20 : 0.0806
Wed 18 Feb 2026 20:39:48 INFO  Saving current: saved/COREtrm-Feb-18-2026_20-39-44.pth
Wed 18 Feb 2026 20:39:51 INFO  epoch 1 training [time: 2.35s, train loss: 253.2523]
Wed 18 Feb 2026 20:39:51 INFO  epoch 1 evaluating [time: 0.16s, valid_score: 0.117300]
Wed 18 Feb 2026 20:39:51 INFO  valid result: 
recall@20 : 0.5421    mrr@20 : 0.1173
Wed 18 Feb 2026 20:39:51 INFO  Saving current: saved/COREtrm-Feb-18-2026_20-39-44.pth
Wed 18 Feb 2026 20:39:53 INFO  epoch 2 training [time: 2.35s, train loss: 212.9566]
Wed 18 Feb 2026 20:39:53 INFO  epoch 2 evaluating [time: 0.16s, valid_score: 0.148900]
Wed 18 Feb 2026 20:39:53 INFO  valid result: 
recall@20 : 0.6291    mrr@20 : 0.1489
Wed 18 Feb 2026 20:39:53 INFO  Saving current: saved/COREtrm-Feb-18-2026_20-39-44.pth
Wed 18 Feb 2026 20:39:56 INFO  epoch 3 training [time: 2.35s, train loss: 200.7375]
Wed 18 Feb 2026 20:39:56 INFO  epoch 3 evaluating [time: 0.16s, valid_score: 0.164300]
Wed 18 Feb 2026 20:39:56 INFO  valid result: 
recall@20 : 0.6566    mrr@20 : 0.1643
Wed 18 Feb 2026 20:39:56 INFO  Saving current: saved/COREtrm-Feb-18-2026_20-39-44.pth
Wed 18 Feb 2026 20:39:58 INFO  epoch 4 training [time: 2.35s, train loss: 196.9528]
Wed 18 Feb 2026 20:39:59 INFO  epoch 4 evaluating [time: 0.16s, valid_score: 0.170500]
Wed 18 Feb 2026 20:39:59 INFO  valid result: 
recall@20 : 0.6676    mrr@20 : 0.1705
Wed 18 Feb 2026 20:39:59 INFO  Saving current: saved/COREtrm-Feb-18-2026_20-39-44.pth
Wed 18 Feb 2026 20:40:01 INFO  epoch 5 training [time: 2.35s, train loss: 195.1256]
Wed 18 Feb 2026 20:40:01 INFO  epoch 5 evaluating [time: 0.16s, valid_score: 0.173900]
Wed 18 Feb 2026 20:40:01 INFO  valid result: 
recall@20 : 0.6691    mrr@20 : 0.1739
Wed 18 Feb 2026 20:40:01 INFO  Saving current: saved/COREtrm-Feb-18-2026_20-39-44.pth
Wed 18 Feb 2026 20:40:04 INFO  epoch 6 training [time: 2.35s, train loss: 194.1824]
Wed 18 Feb 2026 20:40:04 INFO  epoch 6 evaluating [time: 0.16s, valid_score: 0.176400]
Wed 18 Feb 2026 20:40:04 INFO  valid result: 
recall@20 : 0.6701    mrr@20 : 0.1764
Wed 18 Feb 2026 20:40:04 INFO  Saving current: saved/COREtrm-Feb-18-2026_20-39-44.pth
Wed 18 Feb 2026 20:40:06 INFO  epoch 7 training [time: 2.35s, train loss: 193.6794]
Wed 18 Feb 2026 20:40:06 INFO  epoch 7 evaluating [time: 0.16s, valid_score: 0.178000]
Wed 18 Feb 2026 20:40:06 INFO  valid result: 
recall@20 : 0.6734    mrr@20 : 0.178
Wed 18 Feb 2026 20:40:06 INFO  Saving current: saved/COREtrm-Feb-18-2026_20-39-44.pth
Wed 18 Feb 2026 20:40:09 INFO  epoch 8 training [time: 2.35s, train loss: 193.0308]
Wed 18 Feb 2026 20:40:09 INFO  epoch 8 evaluating [time: 0.16s, valid_score: 0.178800]
Wed 18 Feb 2026 20:40:09 INFO  valid result: 
recall@20 : 0.6755    mrr@20 : 0.1788
Wed 18 Feb 2026 20:40:09 INFO  Saving current: saved/COREtrm-Feb-18-2026_20-39-44.pth
Wed 18 Feb 2026 20:40:11 INFO  epoch 9 training [time: 2.35s, train loss: 192.8435]
Wed 18 Feb 2026 20:40:11 INFO  epoch 9 evaluating [time: 0.16s, valid_score: 0.179900]
Wed 18 Feb 2026 20:40:11 INFO  valid result: 
recall@20 : 0.6768    mrr@20 : 0.1799
Wed 18 Feb 2026 20:40:11 INFO  Saving current: saved/COREtrm-Feb-18-2026_20-39-44.pth
Wed 18 Feb 2026 20:40:14 INFO  epoch 10 training [time: 2.35s, train loss: 192.7654]
Wed 18 Feb 2026 20:40:14 INFO  epoch 10 evaluating [time: 0.16s, valid_score: 0.180800]
Wed 18 Feb 2026 20:40:14 INFO  valid result: 
recall@20 : 0.6752    mrr@20 : 0.1808
Wed 18 Feb 2026 20:40:14 INFO  Saving current: saved/COREtrm-Feb-18-2026_20-39-44.pth
Wed 18 Feb 2026 20:40:16 INFO  epoch 11 training [time: 2.36s, train loss: 192.5824]
Wed 18 Feb 2026 20:40:17 INFO  epoch 11 evaluating [time: 0.16s, valid_score: 0.180900]
Wed 18 Feb 2026 20:40:17 INFO  valid result: 
recall@20 : 0.6772    mrr@20 : 0.1809
Wed 18 Feb 2026 20:40:17 INFO  Saving current: saved/COREtrm-Feb-18-2026_20-39-44.pth
Wed 18 Feb 2026 20:40:19 INFO  epoch 12 training [time: 2.35s, train loss: 192.3975]
Wed 18 Feb 2026 20:40:19 INFO  epoch 12 evaluating [time: 0.16s, valid_score: 0.181100]
Wed 18 Feb 2026 20:40:19 INFO  valid result: 
recall@20 : 0.6763    mrr@20 : 0.1811
Wed 18 Feb 2026 20:40:19 INFO  Saving current: saved/COREtrm-Feb-18-2026_20-39-44.pth
Wed 18 Feb 2026 20:40:21 INFO  epoch 13 training [time: 2.35s, train loss: 192.3230]
Wed 18 Feb 2026 20:40:22 INFO  epoch 13 evaluating [time: 0.16s, valid_score: 0.181100]
Wed 18 Feb 2026 20:40:22 INFO  valid result: 
recall@20 : 0.6756    mrr@20 : 0.1811
Wed 18 Feb 2026 20:40:22 INFO  Saving current: saved/COREtrm-Feb-18-2026_20-39-44.pth
Wed 18 Feb 2026 20:40:24 INFO  epoch 14 training [time: 2.35s, train loss: 192.1944]
Wed 18 Feb 2026 20:40:24 INFO  epoch 14 evaluating [time: 0.16s, valid_score: 0.181100]
Wed 18 Feb 2026 20:40:24 INFO  valid result: 
recall@20 : 0.6768    mrr@20 : 0.1811
Wed 18 Feb 2026 20:40:24 INFO  Saving current: saved/COREtrm-Feb-18-2026_20-39-44.pth
Wed 18 Feb 2026 20:40:27 INFO  epoch 15 training [time: 2.35s, train loss: 192.0230]
Wed 18 Feb 2026 20:40:27 INFO  epoch 15 evaluating [time: 0.16s, valid_score: 0.181300]
Wed 18 Feb 2026 20:40:27 INFO  valid result: 
recall@20 : 0.6766    mrr@20 : 0.1813
Wed 18 Feb 2026 20:40:27 INFO  Saving current: saved/COREtrm-Feb-18-2026_20-39-44.pth
Wed 18 Feb 2026 20:40:29 INFO  epoch 16 training [time: 2.35s, train loss: 191.9987]
Wed 18 Feb 2026 20:40:29 INFO  epoch 16 evaluating [time: 0.16s, valid_score: 0.181700]
Wed 18 Feb 2026 20:40:29 INFO  valid result: 
recall@20 : 0.6743    mrr@20 : 0.1817
Wed 18 Feb 2026 20:40:29 INFO  Saving current: saved/COREtrm-Feb-18-2026_20-39-44.pth
Wed 18 Feb 2026 20:40:32 INFO  epoch 17 training [time: 2.35s, train loss: 192.0584]
Wed 18 Feb 2026 20:40:32 INFO  epoch 17 evaluating [time: 0.16s, valid_score: 0.181500]
Wed 18 Feb 2026 20:40:32 INFO  valid result: 
recall@20 : 0.6754    mrr@20 : 0.1815
Wed 18 Feb 2026 20:40:34 INFO  epoch 18 training [time: 2.35s, train loss: 191.9431]
Wed 18 Feb 2026 20:40:35 INFO  epoch 18 evaluating [time: 0.16s, valid_score: 0.181700]
Wed 18 Feb 2026 20:40:35 INFO  valid result: 
recall@20 : 0.6766    mrr@20 : 0.1817
Wed 18 Feb 2026 20:40:35 INFO  Saving current: saved/COREtrm-Feb-18-2026_20-39-44.pth
Wed 18 Feb 2026 20:40:37 INFO  epoch 19 training [time: 2.35s, train loss: 191.9492]
Wed 18 Feb 2026 20:40:37 INFO  epoch 19 evaluating [time: 0.20s, valid_score: 0.182000]
Wed 18 Feb 2026 20:40:37 INFO  valid result: 
recall@20 : 0.677    mrr@20 : 0.182
Wed 18 Feb 2026 20:40:37 INFO  Saving current: saved/COREtrm-Feb-18-2026_20-39-44.pth
Wed 18 Feb 2026 20:40:37 INFO  Loading model structure and parameters from saved/COREtrm-Feb-18-2026_20-39-44.pth
Wed 18 Feb 2026 20:40:37 INFO  best valid : OrderedDict([('recall@20', 0.677), ('mrr@20', 0.182)])
Wed 18 Feb 2026 20:40:37 INFO  test result: OrderedDict([('recall@20', 0.6789), ('mrr@20', 0.1886)])
